{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04363d35",
   "metadata": {},
   "source": [
    "# 02 — Exploratory Data Analysis\n",
    "\n",
    "Structured EDA on `Combined_Dataset_40k.parquet` (40 000 rows, 38 columns).  \n",
    "All figures are saved to `figures/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed66e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup ─────────────────────────────────────────────────────────────\n",
    "import sys, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")          # non-interactive backend for saving\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.05)\n",
    "plt.rcParams.update({\"figure.dpi\": 140, \"savefig.bbox\": \"tight\"})\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "FIG_DIR = PROJECT_ROOT / \"figures\"\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def savefig(name: str):\n",
    "    \"\"\"Save current figure to figures/ as PNG.\"\"\"\n",
    "    path = FIG_DIR / f\"{name}.png\"\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "    print(f\"  Saved → {path.relative_to(PROJECT_ROOT)}\")\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133d6c5",
   "metadata": {},
   "source": [
    "## 1. Load Data & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7275c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PROJECT_ROOT / \"data\" / \"Combined_Dataset_40k.parquet\")\n",
    "print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\\n\")\n",
    "\n",
    "# Convert timestamp_ns back to datetime for time-series work\n",
    "if df[\"timestamp_ns\"].dtype != \"datetime64[ns, UTC]\":\n",
    "    df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_ns\"], unit=\"ns\", utc=True)\n",
    "\n",
    "# Boolean cols stored as boolean dtype – cast to int for numeric ops\n",
    "bool_cols = df.select_dtypes(include=\"boolean\").columns.tolist()\n",
    "for c in bool_cols:\n",
    "    df[c + \"_int\"] = df[c].astype(\"Int64\")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb7ae46",
   "metadata": {},
   "source": [
    "## 2. Missingness Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fab591",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "miss_df = pd.DataFrame({\"missing\": missing, \"pct\": missing_pct}).sort_values(\"pct\", ascending=False)\n",
    "print(miss_df[miss_df[\"missing\"] > 0].to_string() if (miss_df[\"missing\"] > 0).any() else \"No missing values!\")\n",
    "\n",
    "# Visual heatmap (subsample rows for readability)\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sample_idx = np.linspace(0, len(df)-1, 500, dtype=int)\n",
    "sns.heatmap(df.iloc[sample_idx].isnull().T, cbar=False, yticklabels=True,\n",
    "            cmap=\"Reds\", ax=ax)\n",
    "ax.set_title(\"Missingness Heatmap (500-row subsample)\")\n",
    "ax.set_xlabel(\"Row index (subsampled)\")\n",
    "savefig(\"01_missingness_heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ebc3e4",
   "metadata": {},
   "source": [
    "## 3. Dataset-Level Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Distinct Counts ===\")\n",
    "for col in [\"src_device_id\", \"dst_device_id\", \"device_type\", \"vendor\",\n",
    "            \"firmware_version\", \"traffic_type\", \"protocol\", \"attack_type\",\n",
    "            \"severity_level\", \"action_type\", \"controller_state\"]:\n",
    "    if col in df.columns:\n",
    "        print(f\"  {col:30s}  {df[col].nunique():>6}\")\n",
    "\n",
    "print(\"\\n=== Rows per traffic_type ===\")\n",
    "print(df[\"traffic_type\"].value_counts().to_string())\n",
    "\n",
    "print(\"\\n=== Rows per protocol ===\")\n",
    "print(df[\"protocol\"].value_counts().to_string())\n",
    "\n",
    "print(\"\\n=== Rows per device_type ===\")\n",
    "print(df[\"device_type\"].value_counts().to_string())\n",
    "\n",
    "print(\"\\n=== Rows per controller_state ===\")\n",
    "print(df[\"controller_state\"].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb80f7",
   "metadata": {},
   "source": [
    "## 4. Latency & Jitter — Unit Checks + Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd66e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit check: latency_us and jitter_us\n",
    "for col in [\"latency_us\", \"jitter_us\", \"enforcement_latency_us\", \"control_action_delay_us\"]:\n",
    "    if col in df.columns:\n",
    "        s = df[col].dropna()\n",
    "        print(f\"{col:35s}  min={s.min():10.2f}  max={s.max():10.2f}  \"\n",
    "              f\"median={s.median():10.2f}  mean={s.mean():10.2f}\")\n",
    "\n",
    "# Convert to milliseconds for plotting\n",
    "df[\"latency_ms\"]  = df[\"latency_us\"] / 1_000\n",
    "df[\"jitter_ms\"]   = df[\"jitter_us\"]  / 1_000\n",
    "print(\"\\n(Created latency_ms and jitter_ms columns for plotting.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74236249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── latency_us: histogram + log-scale histogram ──────────────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4.5))\n",
    "\n",
    "axes[0].hist(df[\"latency_us\"], bins=80, edgecolor=\"white\", color=\"steelblue\", alpha=0.85)\n",
    "axes[0].set_title(\"Latency (µs) — Linear\")\n",
    "axes[0].set_xlabel(\"latency_us\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "axes[1].hist(df[\"latency_us\"], bins=80, edgecolor=\"white\", color=\"darkorange\", alpha=0.85)\n",
    "axes[1].set_yscale(\"log\")\n",
    "axes[1].set_title(\"Latency (µs) — Log Scale\")\n",
    "axes[1].set_xlabel(\"latency_us\")\n",
    "axes[1].set_ylabel(\"Count (log)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"02_latency_us_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── jitter_us histogram ──────────────────────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(8, 4.5))\n",
    "ax.hist(df[\"jitter_us\"], bins=60, edgecolor=\"white\", color=\"seagreen\", alpha=0.85)\n",
    "ax.set_title(\"Jitter (µs) Distribution\")\n",
    "ax.set_xlabel(\"jitter_us\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "savefig(\"03_jitter_us_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── packet_size_bytes: histogram + boxplot by traffic_type ───────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df[\"packet_size_bytes\"], bins=60, edgecolor=\"white\", color=\"mediumpurple\", alpha=0.85)\n",
    "axes[0].set_title(\"Packet Size (bytes) Distribution\")\n",
    "axes[0].set_xlabel(\"packet_size_bytes\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "\n",
    "order = df[\"traffic_type\"].value_counts().index.tolist()\n",
    "sns.boxplot(data=df, x=\"traffic_type\", y=\"packet_size_bytes\", order=order, ax=axes[1],\n",
    "            palette=\"Set2\")\n",
    "axes[1].set_title(\"Packet Size by Traffic Type\")\n",
    "axes[1].set_xlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"04_packet_size_dist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdedd319",
   "metadata": {},
   "source": [
    "## 5. Scatter — Latency vs Enforcement Latency (color = success_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94ada2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since deadline_us was not merged (no flow_id in spine), we scatter\n",
    "# latency_us vs enforcement_latency_us colored by success_flag instead.\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "scatter_df = df.sample(n=5000, random_state=42)  # subsample for clarity\n",
    "colors = scatter_df[\"success_flag_int\"].map({1: \"tab:green\", 0: \"tab:red\"}).fillna(\"grey\")\n",
    "ax.scatter(scatter_df[\"latency_us\"], scatter_df[\"enforcement_latency_us\"],\n",
    "           c=colors, alpha=0.35, s=8)\n",
    "ax.set_xlabel(\"latency_us\")\n",
    "ax.set_ylabel(\"enforcement_latency_us\")\n",
    "ax.set_title(\"Latency vs Enforcement Latency (green=success, red=fail)\")\n",
    "\n",
    "# Manual legend\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [\n",
    "    Line2D([0],[0], marker=\"o\", color=\"w\", markerfacecolor=\"tab:green\", markersize=7, label=\"success=True\"),\n",
    "    Line2D([0],[0], marker=\"o\", color=\"w\", markerfacecolor=\"tab:red\",   markersize=7, label=\"success=False\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\")\n",
    "savefig(\"05_latency_vs_enforcement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08831f",
   "metadata": {},
   "source": [
    "## 6. Correlation Heatmap + Top-15 Correlated with latency_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b29c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "num_df = df.select_dtypes(include=[np.number])\n",
    "# Drop id-like and raw timestamp columns for cleaner heatmap\n",
    "drop_ids = [c for c in num_df.columns if c.endswith(\"_id\") or c == \"timestamp_ns\"\n",
    "            or c == \"event_id\" or c == \"action_id\"]\n",
    "num_df = num_df.drop(columns=drop_ids, errors=\"ignore\")\n",
    "\n",
    "corr = num_df.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt=\".2f\", cmap=\"RdBu_r\",\n",
    "            center=0, linewidths=0.4, ax=ax, annot_kws={\"size\": 7},\n",
    "            vmin=-1, vmax=1)\n",
    "ax.set_title(\"Correlation Heatmap (numeric features)\")\n",
    "savefig(\"06_correlation_heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915eb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-15 features correlated with latency_us\n",
    "if \"latency_us\" in corr.columns:\n",
    "    top15 = corr[\"latency_us\"].drop(\"latency_us\", errors=\"ignore\").abs().sort_values(ascending=False).head(15)\n",
    "    print(\"Top-15 features correlated with latency_us (abs):\\n\")\n",
    "    for feat, val in top15.items():\n",
    "        raw = corr.loc[feat, \"latency_us\"]\n",
    "        print(f\"  {feat:35s}  r = {raw:+.4f}  (|r| = {val:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf745a",
   "metadata": {},
   "source": [
    "## 7. Timeline — High-Activity Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the device with the most rows\n",
    "top_device = df[\"src_device_id\"].value_counts().idxmax()\n",
    "dev_df = df[df[\"src_device_id\"] == top_device].copy()\n",
    "dev_df = dev_df.sort_values(\"timestamp_utc\").set_index(\"timestamp_utc\")\n",
    "print(f\"Device {top_device}: {len(dev_df)} rows, \"\n",
    "      f\"time range {dev_df.index.min()} → {dev_df.index.max()}\")\n",
    "\n",
    "# Resample to 1-second bins\n",
    "rs = dev_df.resample(\"1s\").agg({\n",
    "    \"latency_us\":      \"mean\",\n",
    "    \"queue_occupancy\":  \"mean\",\n",
    "    \"packet_size_bytes\": \"count\",     # proxy for packet_rate\n",
    "}).rename(columns={\"packet_size_bytes\": \"packet_rate\"})\n",
    "rs = rs.dropna(how=\"all\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(rs.index, rs[\"latency_us\"], color=\"steelblue\", lw=0.8)\n",
    "axes[0].set_ylabel(\"latency_us (mean)\")\n",
    "axes[0].set_title(f\"Device {top_device} — 1-s Resampled Timeline\")\n",
    "\n",
    "axes[1].plot(rs.index, rs[\"queue_occupancy\"], color=\"darkorange\", lw=0.8)\n",
    "axes[1].set_ylabel(\"queue_occupancy (mean)\")\n",
    "\n",
    "axes[2].bar(rs.index, rs[\"packet_rate\"], width=pd.Timedelta(\"0.8s\"), color=\"seagreen\", alpha=0.7)\n",
    "axes[2].set_ylabel(\"packet_rate (count/s)\")\n",
    "axes[2].set_xlabel(\"Time (UTC)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "savefig(\"07_device_timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeaf8b",
   "metadata": {},
   "source": [
    "## 8. Attack Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673f50e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an attack presence indicator\n",
    "# anomaly_label is all 1/True in this dataset, so use attack_type instead.\n",
    "attack_df = df[[\"timestamp_utc\", \"attack_type\"]].copy()\n",
    "attack_df = attack_df.sort_values(\"timestamp_utc\").set_index(\"timestamp_utc\")\n",
    "\n",
    "# Count events per 1-second bucket, split by attack_type\n",
    "attack_ts = attack_df.groupby(\"attack_type\").resample(\"1s\").size().unstack(level=0, fill_value=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "colors = sns.color_palette(\"Set1\", n_colors=attack_ts.shape[1])\n",
    "for i, col in enumerate(attack_ts.columns):\n",
    "    ax.plot(attack_ts.index, attack_ts[col], label=col, lw=0.6, alpha=0.8, color=colors[i])\n",
    "\n",
    "ax.set_title(\"Attack Event Count by Type (1-s bins)\")\n",
    "ax.set_xlabel(\"Time (UTC)\")\n",
    "ax.set_ylabel(\"Events / second\")\n",
    "ax.legend(fontsize=8, loc=\"upper right\")\n",
    "savefig(\"08_attack_timeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2041913",
   "metadata": {},
   "source": [
    "## 9. Additional Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fc72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Latency by traffic_type violin plot ──────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.violinplot(data=df, x=\"traffic_type\", y=\"latency_us\", palette=\"muted\", ax=ax,\n",
    "               inner=\"quart\", cut=0)\n",
    "ax.set_title(\"Latency Distribution by Traffic Type\")\n",
    "ax.set_xlabel(\"\")\n",
    "savefig(\"09_latency_by_traffic_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Controller state vs queue_occupancy boxplot ──────────────────────\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "sns.boxplot(data=df, x=\"controller_state\", y=\"queue_occupancy\", palette=\"Pastel1\", ax=ax)\n",
    "ax.set_title(\"Queue Occupancy by Controller State\")\n",
    "ax.set_xlabel(\"\")\n",
    "savefig(\"10_queue_by_controller_state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6edebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Success flag rate by severity_level ──────────────────────────────\n",
    "success_by_severity = df.groupby(\"severity_level\")[\"success_flag_int\"].mean().sort_values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "success_by_severity.plot.barh(ax=ax, color=\"teal\", edgecolor=\"white\")\n",
    "ax.set_xlabel(\"Success Rate\")\n",
    "ax.set_title(\"Enforcement Success Rate by Severity Level\")\n",
    "ax.set_xlim(0, 1)\n",
    "for i, v in enumerate(success_by_severity):\n",
    "    ax.text(v + 0.01, i, f\"{v:.2%}\", va=\"center\", fontsize=9)\n",
    "savefig(\"11_success_rate_by_severity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0fc83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Pair plot of key numeric features (subsample) ────────────────────\n",
    "pair_cols = [\"latency_us\", \"jitter_us\", \"queue_occupancy\",\n",
    "             \"enforcement_latency_us\", \"control_action_delay_us\"]\n",
    "pair_df = df[pair_cols + [\"traffic_type\"]].sample(2000, random_state=42)\n",
    "\n",
    "g = sns.pairplot(pair_df, hue=\"traffic_type\", palette=\"Set2\",\n",
    "                 plot_kws={\"s\": 10, \"alpha\": 0.5}, diag_kws={\"alpha\": 0.6},\n",
    "                 height=2.2)\n",
    "g.figure.suptitle(\"Pair Plot — Key Metrics (2k subsample)\", y=1.02)\n",
    "g.savefig(FIG_DIR / \"12_pair_plot.png\", dpi=120)\n",
    "plt.close()\n",
    "print(\"  Saved → figures/12_pair_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f347c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved figures\n",
    "print(\"\\n=== Figures saved ===\")\n",
    "for f in sorted(FIG_DIR.glob(\"*.png\")):\n",
    "    size_kb = f.stat().st_size / 1024\n",
    "    print(f\"  {f.relative_to(PROJECT_ROOT)}  ({size_kb:.0f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a8700",
   "metadata": {},
   "source": [
    "---\n",
    "**Next step:** see `reports/eda_summary.md` for key observations and recommended features."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

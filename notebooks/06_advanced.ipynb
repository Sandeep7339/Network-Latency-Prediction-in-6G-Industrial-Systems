{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dd983c",
   "metadata": {},
   "source": [
    "# 06 — Advanced Models: XGBoost-ES + LSTM\n",
    "\n",
    "Trains two advanced model families and compares them against Phase-5 baselines:\n",
    "\n",
    "| Model | Type | Notes |\n",
    "|-------|------|-------|\n",
    "| XGBoost-ES | Tree ensemble | Early stopping (patience=30, up to 500 rounds) |\n",
    "| LSTM | Sequence (PyTorch) | 2-layer, hidden=64, seq_len=30, global sliding window |\n",
    "\n",
    "Both regression (`latency_us`) and classification (`latency_violation >120µs`) tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, warnings, os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "os.chdir(os.path.join(os.path.dirname(os.path.abspath('__file__')), '..'))\n",
    "sys.path.insert(0, os.getcwd())\n",
    "warnings.filterwarnings('ignore', message='X does not have valid feature names')\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb064e",
   "metadata": {},
   "source": [
    "## 1. Train advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f135d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "from src.models.advanced import main as train_advanced\n",
    "adv_metrics = train_advanced()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35a0a5",
   "metadata": {},
   "source": [
    "## 2. LSTM training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Regression LSTM loss\n",
    "h = adv_metrics['lstm_reg']['history']\n",
    "ax1.plot(h['train_loss'], label='train')\n",
    "ax1.plot(h['val_loss'], label='val')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('MSE Loss')\n",
    "ax1.set_title(f\"LSTM Regression — best epoch {adv_metrics['lstm_reg']['best_epoch']}\")\n",
    "ax1.legend()\n",
    "\n",
    "# Classification LSTM loss\n",
    "h = adv_metrics['lstm_clf']['history']\n",
    "ax2.plot(h['train_loss'], label='train')\n",
    "ax2.plot(h['val_loss'], label='val')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('BCE Loss')\n",
    "ax2.set_title(f\"LSTM Classification — best epoch {adv_metrics['lstm_clf']['best_epoch']}\")\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('LSTM Training Curves', fontsize=13)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/lstm_training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d6670",
   "metadata": {},
   "source": [
    "## 3. XGBoost early-stopping curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b1fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "xgb_bundle = joblib.load('models/advanced_xgb.joblib')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "evals_reg = xgb_bundle['evals_reg']\n",
    "for key in evals_reg:\n",
    "    metric_name = list(evals_reg[key].keys())[0]\n",
    "    ax1.plot(evals_reg[key][metric_name], label=key)\n",
    "ax1.set_xlabel('Boosting Round')\n",
    "ax1.set_ylabel(metric_name.upper())\n",
    "ax1.set_title(f'XGBoost Regression — best iter {adv_metrics[\"xgb_reg\"][\"best_iteration\"]}')\n",
    "ax1.legend()\n",
    "\n",
    "evals_clf = xgb_bundle['evals_clf']\n",
    "for key in evals_clf:\n",
    "    metric_name = list(evals_clf[key].keys())[0]\n",
    "    ax2.plot(evals_clf[key][metric_name], label=key)\n",
    "ax2.set_xlabel('Boosting Round')\n",
    "ax2.set_ylabel(metric_name)\n",
    "ax2.set_title(f'XGBoost Classification — best iter {adv_metrics[\"xgb_clf\"][\"best_iteration\"]}')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('XGBoost Early-Stopping Curves', fontsize=13)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/xgb_es_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4adb7c7",
   "metadata": {},
   "source": [
    "## 4. Run comparison pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf43aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.compare import main as run_compare\n",
    "comp = run_compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a39400",
   "metadata": {},
   "source": [
    "## 5. Comparison bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='figures/model_comparison.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8991e341",
   "metadata": {},
   "source": [
    "## 6. Test-set metrics tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68339a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "reg = comp['regression']\n",
    "reg_df = pd.DataFrame(reg).T\n",
    "print('REGRESSION')\n",
    "display(reg_df[['mae','rmse','r2']].round(4))\n",
    "\n",
    "# Classification\n",
    "clf = comp['classification']\n",
    "clf_df = pd.DataFrame(clf).T\n",
    "print('\\nCLASSIFICATION')\n",
    "display(clf_df[['accuracy','f1','roc_auc','avg_precision']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad00f2f",
   "metadata": {},
   "source": [
    "## 7. Bootstrap test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7da561",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot = comp['bootstrap_xgb_reg']\n",
    "print('Bootstrap paired test: Baseline XGB vs Advanced XGB (MAE)')\n",
    "print(f\"  Baseline MAE:  {boot['metric_a']:.4f}\")\n",
    "print(f\"  Advanced MAE:  {boot['metric_b']:.4f}\")\n",
    "print(f\"  Diff (bl-adv): {boot['diff_a_minus_b']:.4f}\")\n",
    "print(f\"  p-value:       {boot['p_value']:.4f}\")\n",
    "print(f\"  95% CI:        [{boot['ci_95_lower']:.4f}, {boot['ci_95_upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d995632",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "1. **XGBoost-ES regression** early-stopped at ~31 rounds — additional rounds\n",
    "   provide no benefit on this synthetic data, confirming the near-zero signal.\n",
    "\n",
    "2. **LSTM regression** converges to MSE ≈ 226 (RMSE ≈ 15 µs) matching the\n",
    "   expected variance of a uniform distribution, comparable to the mean predictor.\n",
    "\n",
    "3. **All models cluster around the same error floor** (MAE ≈ 12 µs).\n",
    "   With genuine temporal patterns in real data, the LSTM's sequential\n",
    "   context and XGBoost's early-stopping would be expected to dominate.\n",
    "\n",
    "4. **Bootstrap p-value**: the difference between baseline and advanced\n",
    "   XGBoost MAE is statistically measurable but practically negligible\n",
    "   given the synthetic data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

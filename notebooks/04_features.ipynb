{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9d2e5f",
   "metadata": {},
   "source": [
    "# 04 — Feature Pipeline\n",
    "\n",
    "Demonstrates the preprocessing pipeline: rolling/lag feature creation,\n",
    "categorical encoding, scaling, and persisted `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc5ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915c53",
   "metadata": {},
   "source": [
    "## 1. Run the full pipeline (or load saved artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from src.features.feature_pipeline import (\n",
    "    build_pipeline, prepare_dataset, get_feature_names,\n",
    "    RollingLagFeatures, build_column_transformer,\n",
    ")\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"Combined_Dataset_40k.parquet\"\n",
    "PIPELINE_PATH = PROJECT_ROOT / \"models\" / \"preprocess_pipeline.joblib\"\n",
    "\n",
    "# Build from scratch (also saves pipeline + train_ready.parquet)\n",
    "X, y, feature_names, ct = build_pipeline(\n",
    "    parquet_path=DATA_PATH,\n",
    "    save_dir=PROJECT_ROOT / \"models\",\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"NaN count in X: {np.isnan(X).sum()}\")\n",
    "print(f\"Feature count: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ee3bb",
   "metadata": {},
   "source": [
    "## 2. List all feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = pd.DataFrame({\n",
    "    \"idx\": range(1, len(feature_names) + 1),\n",
    "    \"feature\": feature_names,\n",
    "})\n",
    "feat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d6ffc",
   "metadata": {},
   "source": [
    "## 3. Load the saved pipeline and transform a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the persisted pipeline\n",
    "ct_loaded = joblib.load(PIPELINE_PATH)\n",
    "print(f\"Loaded pipeline from {PIPELINE_PATH}\")\n",
    "print(f\"Pipeline transformers: {[t[0] for t in ct_loaded.transformers]}\")\n",
    "\n",
    "# Load train_ready and transform a 100-row sample\n",
    "train_ready = pd.read_parquet(PROJECT_ROOT / \"data\" / \"train_ready.parquet\")\n",
    "sample = train_ready.sample(100, random_state=42)\n",
    "X_sample = ct_loaded.transform(sample)\n",
    "\n",
    "print(f\"\\nSample X shape: {X_sample.shape}\")\n",
    "print(f\"NaNs in sample X: {np.isnan(X_sample).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 rows as a DataFrame\n",
    "sample_df = pd.DataFrame(X_sample[:5], columns=feature_names)\n",
    "sample_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc260a41",
   "metadata": {},
   "source": [
    "## 4. Feature group breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db7bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_pipeline import (\n",
    "    PACKET_FLOW_COLS, DEVICE_COLS, TIMING_COLS,\n",
    "    QUEUE_CONTROLLER_COLS, SECURITY_COLS,\n",
    "    CAT_ONEHOT_COLS, CAT_ORDINAL_COLS, CAT_FREQ_COLS,\n",
    "    ROLLING_WINDOWS_SEC, LAG_STEPS,\n",
    ")\n",
    "\n",
    "groups = {\n",
    "    \"Packet / Flow\":      PACKET_FLOW_COLS,\n",
    "    \"Device\":             DEVICE_COLS,\n",
    "    \"Timing\":             TIMING_COLS,\n",
    "    \"Queue / Controller\": QUEUE_CONTROLLER_COLS,\n",
    "    \"Security\":           SECURITY_COLS,\n",
    "    \"Rolling features\":   [f\"latency_roll_*_{w}s, packet_rate_{w}s\" for w in ROLLING_WINDOWS_SEC],\n",
    "    \"Lag features\":       [f\"latency_lag_{l}\" for l in LAG_STEPS],\n",
    "    \"One-hot encoded\":    CAT_ONEHOT_COLS,\n",
    "    \"Ordinal encoded\":    CAT_ORDINAL_COLS,\n",
    "    \"Frequency encoded\":  CAT_FREQ_COLS,\n",
    "}\n",
    "\n",
    "for gname, cols in groups.items():\n",
    "    print(f\"\\n{gname} ({len(cols)} raw columns):\")\n",
    "    for c in cols:\n",
    "        print(f\"  • {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e8d89",
   "metadata": {},
   "source": [
    "## 5. Quick statistics on transformed X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "X_df.describe().T.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution\n",
    "print(f\"Target (success_flag) distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nPositive rate: {y.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa912d",
   "metadata": {},
   "source": [
    "---\n",
    "**Artifacts saved:**\n",
    "- `models/preprocess_pipeline.joblib`\n",
    "- `data/train_ready.parquet`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d79d2b",
   "metadata": {},
   "source": [
    "# 11 — Final Ensemble & Online Prediction Demo\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading the **stacking ensemble** (`models/final_ensemble.joblib`)\n",
    "2. Reviewing **final evaluation metrics** (`reports/final_metrics.json`)\n",
    "3. Running **online prediction** on a sample JSON batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c61a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib, json\n",
    "ROOT = pathlib.Path.cwd().parent\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from IPython.display import display, JSON, Image, Markdown\n",
    "import pandas as pd\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ac2ac",
   "metadata": {},
   "source": [
    "## 1. Final Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c51f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = json.loads((ROOT / \"reports\" / \"final_metrics.json\").read_text())\n",
    "\n",
    "# Regression comparison\n",
    "reg_rows = []\n",
    "for key, label in [(\"ensemble_reg\", \"Ensemble\"), (\"xgb_reg\", \"XGBoost\"),\n",
    "                    (\"lgb_reg\", \"LightGBM\"), (\"ridge_reg\", \"Ridge\")]:\n",
    "    m = metrics[key]\n",
    "    reg_rows.append({\"Model\": label, \"MAE\": m[\"mae\"], \"RMSE\": m[\"rmse\"], \"R²\": m[\"r2\"]})\n",
    "print(\"Regression (test set):\")\n",
    "display(pd.DataFrame(reg_rows).set_index(\"Model\").round(4))\n",
    "\n",
    "# Classification comparison\n",
    "clf_rows = []\n",
    "for key, label in [(\"ensemble_clf\", \"Ensemble\"), (\"xgb_clf\", \"XGBoost\"),\n",
    "                    (\"lgb_clf\", \"LightGBM\"), (\"lr_clf\", \"LogReg\")]:\n",
    "    m = metrics[key]\n",
    "    clf_rows.append({\"Model\": label, \"F1\": m.get(\"f1\",0), \"AUC\": m.get(\"roc_auc\",0),\n",
    "                     \"Accuracy\": m.get(\"accuracy\",0)})\n",
    "print(\"\\nClassification (test set):\")\n",
    "display(pd.DataFrame(clf_rows).set_index(\"Model\").round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cbdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(str(ROOT / \"figures\" / \"final_metrics.png\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c97663",
   "metadata": {},
   "source": [
    "## 2. Load Ensemble Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60860846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.feature_pipeline import FrequencyEncoder\n",
    "from src.models.ensemble import StackingEnsemble\n",
    "import joblib\n",
    "\n",
    "ens = joblib.load(ROOT / \"models\" / \"final_ensemble.joblib\")\n",
    "print(\"Ensemble keys:\", list(ens.keys()))\n",
    "print(\"Reg base learners:\", [type(m).__name__ for m in ens['reg'].base_models])\n",
    "print(\"Clf base learners:\", [type(m).__name__ for m in ens['clf'].base_models])\n",
    "print(\"Meta-learner (reg):\", type(ens['reg'].meta_model).__name__)\n",
    "print(\"Meta-learner (clf):\", type(ens['clf'].meta_model).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9639a",
   "metadata": {},
   "source": [
    "## 3. Online Prediction Demo\n",
    "\n",
    "Read `examples/sample_input.json`, run through the prediction pipeline,\n",
    "and write `examples/sample_output.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea28cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show input\n",
    "inp = json.loads((ROOT / \"examples\" / \"sample_input.json\").read_text())\n",
    "print(f\"Input: {len(inp['flows'])} flow(s)\")\n",
    "display(pd.DataFrame(inp[\"flows\"])[[\"src_device_id\", \"dst_device_id\",\n",
    "    \"traffic_type\", \"packet_size_bytes\", \"controller_state\", \"attack_type\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77633bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.predict.online_predict import read_input, predict, write_output\n",
    "\n",
    "df_in = read_input(ROOT / \"examples\" / \"sample_input.json\")\n",
    "preds = predict(df_in, ens)\n",
    "\n",
    "out_path = ROOT / \"examples\" / \"sample_output.json\"\n",
    "write_output(preds, out_path)\n",
    "\n",
    "display(pd.DataFrame(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify output file\n",
    "out = json.loads(out_path.read_text())\n",
    "print(\"Output file predictions:\")\n",
    "for p in out[\"predictions\"]:\n",
    "    flag = \"VIOLATION\" if p[\"violation_flag\"] else \"ok\"\n",
    "    print(f\"  flow {p['flow_index']}: \"\n",
    "          f\"latency={p['predicted_latency_us']:.2f} μs  \"\n",
    "          f\"P(violation)={p['violation_probability']:.4f}  [{flag}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405b60f",
   "metadata": {},
   "source": [
    "## 4. CLI equivalent\n",
    "\n",
    "The same prediction can be run from the command line:\n",
    "\n",
    "```bash\n",
    "python -m src.predict.online_predict \\\n",
    "    --input  examples/sample_input.json \\\n",
    "    --output examples/sample_output.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
